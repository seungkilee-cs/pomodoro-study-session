{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "standard-nevada",
   "metadata": {},
   "source": [
    "# 210315_study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-belly",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "You want to build a word cloud, an infographic where the size of a word corresponds to how often it appears in the body of text.\n",
    "\n",
    "To do this, you'll need data. Write code that takes a long string and builds its word cloud data in a dictionary â†´ , where the keys are words and the values are the number of times the words occurred.\n",
    "\n",
    "Think about capitalized words. For example, look at these sentences:\n",
    "\n",
    "  'After beating the eggs, Dana read the next step:'\n",
    "'Add milk and eggs, then add flour and sugar.'\n",
    "What do we want to do with \"After\", \"Dana\", and \"add\"? In this example, your final dictionary should include one \"Add\" or \"add\" with a value of 2. Make reasonable (not necessarily perfect) decisions about cases like \"After\" and \"Dana\".\n",
    "\n",
    "Assume the input will only contain words and standard punctuation.\n",
    "\n",
    "You could make a reasonable argument to use regex in your solution. We won't, mainly because performance is difficult to measure and can get pretty bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-upgrade",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "1. strip punctuations\n",
    "2. split on whitespace for words\n",
    "3. if word exists in dict, add 1 to the count.\n",
    "4. if word doesn't exist and is not empty, add the word to dict\n",
    "5. check to see if upper/lower case of the word is in the dictionary. if the word appears more than once, lower case it. If not, keep it at upper case.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-copper",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "automotive-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_counts(sentence: str) -> dict:\n",
    "    res = {}\n",
    "    allowed = [\"'\"]\n",
    "    # o(m), m being the number of spaces = n-1\n",
    "    # heuristic for handling ... in a quick and dirty fashion\n",
    "    wordList = sentence.replace(\"...\", \", \").split()\n",
    "    \n",
    "    for word in wordList:\n",
    "        # if word has punc\n",
    "        if word[-1] not in allowed and not word[-1].isalpha():\n",
    "            word = word[0:-1]\n",
    "        if word in res.keys():\n",
    "            res[word] += 1\n",
    "        # check for both cases\n",
    "        elif word.title() in res.keys() or word.lower() in res.keys():\n",
    "            # if upper case exists, remove the upper case and assign the current count to lower case\n",
    "            if res[word.title()]:\n",
    "                currentCnt = res[word.title()]\n",
    "                del res[word.title()]\n",
    "                res[word.lower()] = currentCnt\n",
    "            # either way, we just need to add one more to the lower of the occurence.\n",
    "            res[word.lower()] += 1\n",
    "        # only add if the word is not '', in case there were single punctuation in between white spaces\n",
    "        elif word:\n",
    "            res[word] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-imperial",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beneficial-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS\n",
      "PASS\n",
      "PASS\n",
      "PASS\n",
      "PASS\n",
      "PASS\n"
     ]
    }
   ],
   "source": [
    "def assertTest(actual, expected):\n",
    "    if actual == expected:\n",
    "        print(\"PASS\")\n",
    "    else:\n",
    "        print(\"FAIL\")\n",
    "\n",
    "def test_simple_sentence():\n",
    "    input = 'I like cake'\n",
    "\n",
    "    actual = words_to_counts(input)\n",
    "\n",
    "    expected = {'I': 1, 'like': 1, 'cake': 1}\n",
    "    assertTest(actual, expected)\n",
    "\n",
    "def test_longer_sentence():\n",
    "    input = 'Chocolate cake for dinner and pound cake for dessert'\n",
    "\n",
    "    actual = words_to_counts(input)\n",
    "\n",
    "    expected = {\n",
    "        'and': 1,\n",
    "        'pound': 1,\n",
    "        'for': 2,\n",
    "        'dessert': 1,\n",
    "        'Chocolate': 1,\n",
    "        'dinner': 1,\n",
    "        'cake': 2,\n",
    "    }\n",
    "    assertTest(actual, expected)\n",
    "\n",
    "def test_punctuation():\n",
    "    input = 'Strawberry short cake? Yum!'\n",
    "\n",
    "    actual = words_to_counts(input)\n",
    "\n",
    "    expected = {'cake': 1, 'Strawberry': 1, 'short': 1, 'Yum': 1}\n",
    "    assertTest(actual, expected)\n",
    "\n",
    "def test_hyphenated_words():\n",
    "    input = 'Dessert - mille-feuille cake'\n",
    "\n",
    "    actual = words_to_counts(input)\n",
    "\n",
    "    expected = {'cake': 1, 'Dessert': 1, 'mille-feuille': 1}\n",
    "    assertTest(actual, expected)\n",
    "\n",
    "def test_ellipses_between_words():\n",
    "    input = 'Mmm...mmm...decisions...decisions'\n",
    "\n",
    "    actual = words_to_counts(input)\n",
    "\n",
    "    expected = {'mmm': 2, 'decisions': 2}\n",
    "    assertTest(actual, expected)\n",
    "\n",
    "def test_apostrophes():\n",
    "    input = \"Allie's Bakery: Sasha's Cakes\"\n",
    "\n",
    "    actual = words_to_counts(input)\n",
    "\n",
    "    expected = {\"Bakery\": 1, \"Cakes\": 1, \"Allie's\": 1, \"Sasha's\": 1}\n",
    "    assertTest(actual, expected)\n",
    "    \n",
    "test_simple_sentence()\n",
    "test_longer_sentence()\n",
    "test_punctuation()\n",
    "test_hyphenated_words()\n",
    "test_ellipses_between_words()\n",
    "test_apostrophes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-chemical",
   "metadata": {},
   "source": [
    "## Complexity\n",
    "\n",
    "### Time\n",
    "\n",
    "- `replace()` -> `O(n)`, as we go through every char in the string of length n\n",
    "- `split()` -> `O(n)`, as we go through every char to find the split char\n",
    "- `forloop` -> `O(m)`, the length of the word list\n",
    "- Strip punctuation -> `O(1) + O(1)` -> `O(1)`\n",
    "- Check word in dict -> `O(d)`, where `d` is the size of current dictionary is represented as `m - r`, where `i` is the current iteration and `r` is number of repeating word.\n",
    "- Duplicate handling -> `O((n/m) + d)`, `n/m` represents the length of the average word in the list (total char / len(wordList)), and `d` is the size of the dictionary represented as `m - r`\n",
    "- rest of the operations are O(1)\n",
    "\n",
    "Basic mathematics implies following relationship between these variables\n",
    "\n",
    "$n \\geq m$ because we are going to remove at least 0 whitespace.\n",
    "\n",
    "$m \\geq d$ because we are going to have at least 0 duplicates.\n",
    "\n",
    "$\\therefore n \\geq m \\geq d$\n",
    "\n",
    "Therefore, the dominant term in the algorithm is `n` and the time complexity grows linearly with the input size `n` asymptotically -> `O(n)`\n",
    "\n",
    "### Space\n",
    "\n",
    "Constant space to hold the allowed characters, O(n) space to hold the words and O(n) space to build the dictionary. Here the space complexity becomes `O(n)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-treasurer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
